#!/usr/bin/env python3
"""
Multi-Timeframe Trading Model V4 - INSTITUTIONAL APPROACH
=========================================================
Target: 75%+ win rate with multi-timeframe analysis and news filtering

PROFESSIONAL FEATURES:
1. Multi-timeframe trend analysis (1D, 4H, 1H for filtering, 15M for execution)
2. News sentiment analysis from Forex Factory for XAUUSD
3. Market session awareness and volatility regimes
4. Institutional-grade signal filtering
5. Risk-on/Risk-off market sentiment detection
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src', 'indicators'))

import numpy as np
import pandas as pd
import pandas_ta as pta
import torch
import torch.nn as nn
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.monitor import Monitor
from datetime import datetime, timedelta
import gymnasium as gym
from gymnasium import spaces
import requests
import warnings
warnings.filterwarnings('ignore')


# ============================================================================
# NEWS AND SENTIMENT ANALYSIS
# ============================================================================

class NewsAnalyzer:
    """Forex Factory news analyzer for XAUUSD sentiment."""
    
    def __init__(self):
        self.news_cache = {}
        self.last_update = None
        self.gold_keywords = [
            'gold', 'xau', 'precious metals', 'inflation', 'fed', 'interest rates',
            'dollar', 'dxy', 'unemployment', 'cpi', 'ppi', 'fomc', 'powell',
            'treasury', 'yield', 'gdp', 'nfp', 'retail sales', 'pce'
        ]
        
    def get_news_sentiment(self, date):
        """Get news sentiment for given date."""
        try:
            # Check cache first
            date_str = date.strftime('%Y-%m-%d')
            if date_str in self.news_cache:
                return self.news_cache[date_str]
            
            # Simulate news sentiment (in production, use real Forex Factory API)
            # For now, create realistic sentiment based on market patterns
            sentiment = self._simulate_news_sentiment(date)
            self.news_cache[date_str] = sentiment
            return sentiment
            
        except Exception as e:
            print(f"News analysis error: {e}")
            return {'sentiment': 0, 'impact': 'low', 'risk_on': 0.5}
    
    def _simulate_news_sentiment(self, date):
        """Simulate realistic news sentiment for XAUUSD."""
        # Create realistic patterns based on day of week and time
        weekday = date.weekday()
        hour = date.hour
        
        # Higher volatility during US session and news releases
        base_sentiment = 0.0
        impact = 'low'
        risk_on = 0.5
        
        # Monday: Weekend gap effects
        if weekday == 0:
            base_sentiment = np.random.normal(0, 0.3)
            impact = 'medium'
            
        # Tuesday-Thursday: Main trading days
        elif weekday in [1, 2, 3]:
            if 8 <= hour <= 10:  # London open
                base_sentiment = np.random.normal(0, 0.4)
                impact = 'medium'
            elif 13 <= hour <= 15:  # US open overlap
                base_sentiment = np.random.normal(0, 0.5)
                impact = 'high'
            else:
                base_sentiment = np.random.normal(0, 0.2)
                
        # Friday: Position squaring
        elif weekday == 4:
            if hour >= 15:  # Friday afternoon
                base_sentiment = np.random.normal(-0.1, 0.3)  # Slight risk-off bias
                impact = 'medium'
            else:
                base_sentiment = np.random.normal(0, 0.2)
        
        # Weekend: Low impact
        else:
            base_sentiment = np.random.normal(0, 0.1)
            impact = 'low'
        
        # Risk-on/Risk-off sentiment
        if base_sentiment > 0.3:
            risk_on = 0.7  # Risk-on (bearish for gold)
        elif base_sentiment < -0.3:
            risk_on = 0.3  # Risk-off (bullish for gold)
        else:
            risk_on = 0.5  # Neutral
            
        return {
            'sentiment': np.clip(base_sentiment, -1, 1),
            'impact': impact,
            'risk_on': risk_on
        }


# ============================================================================
# MULTI-TIMEFRAME ANALYSIS
# ============================================================================

def load_multi_timeframe_data(base_path="data/raw"):
    """Load actual multi-timeframe data from files."""
    
    print("ÔøΩ Loading  multi-timeframe data from files...")
    
    # Load all timeframes
    timeframes = {
        '15M': f"{base_path}/XAU_15m_data.csv",
        '1H': f"{base_path}/XAU_1h_data.csv", 
        '4H': f"{base_path}/XAU_4h_data.csv",
        '1D': f"{base_path}/XAU_1d_data.csv"
    }
    
    dfs = {}
    
    for tf, filepath in timeframes.items():
        try:
            # Load data
            df = pd.read_csv(filepath, sep=';')
            if len(df.columns) == 1:
                df = pd.read_csv(filepath, sep=',')
            
            # Handle datetime
            for col in ['Date', 'date', 'datetime', 'Gmt time']:
                if col in df.columns:
                    df['Date'] = pd.to_datetime(df[col])
                    df.set_index('Date', inplace=True)
                    break
            
            df.sort_index(inplace=True)
            dfs[tf] = df
            print(f"  ‚úÖ {tf}: {len(df):,} bars loaded")
            
        except Exception as e:
            print(f"  ‚ùå Error loading {tf}: {e}")
            dfs[tf] = None
    
    return dfs


def create_multi_timeframe_signals(df_15m, df_1h=None, df_4h=None, df_1d=None):
    """Create multi-timeframe signals using actual timeframe data."""
    
    print("üîß Creating professional multi-timeframe analysis...")
    
    # Add technical indicators to each timeframe
    df_15m = add_technical_indicators(df_15m.copy(), '15M')
    
    if df_1h is not None:
        df_1h = add_technical_indicators(df_1h.copy(), '1H')
    if df_4h is not None:
        df_4h = add_technical_indicators(df_4h.copy(), '4H')
    if df_1d is not None:
        df_1d = add_technical_indicators(df_1d.copy(), '1D')
    
    # Create trend filters using actual higher timeframe data
    df_15m = add_real_timeframe_filters(df_15m, df_1h, df_4h, df_1d)
    
    # Add market session analysis
    df_15m = add_session_analysis(df_15m)
    
    # Add news sentiment (simulated but realistic)
    df_15m = add_news_sentiment(df_15m)
    
    # Create final institutional signals
    df_15m = create_institutional_signals(df_15m)
    
    return df_15m


def add_real_timeframe_filters(df_15m, df_1h, df_4h, df_1d):
    """Add multi-timeframe trend filters using real timeframe data."""
    
    print("  üìä Aligning multi-timeframe trends...")
    
    df_15m = df_15m.copy()
    
    # Initialize higher timeframe columns
    df_15m['h1_trend'] = 0
    df_15m['h4_trend'] = 0  
    df_15m['d1_trend'] = 0
    df_15m['h1_strength'] = 0
    df_15m['h4_strength'] = 0
    df_15m['d1_strength'] = 0
    
    # Align higher timeframe data with 15M bars
    for i in range(len(df_15m)):
        try:
            # Get the timestamp for current 15M bar
            if hasattr(df_15m.index, 'to_pydatetime'):
                current_time = df_15m.index[i]
            else:
                # If no datetime index, create approximate alignment
                base_time = pd.Timestamp('2023-01-01')
                current_time = base_time + pd.Timedelta(minutes=15*i)
            
            # Get 1H trend
            if df_1h is not None:
                h1_data = get_aligned_timeframe_data(df_1h, current_time, '1H')
                if h1_data is not None:
                    df_15m.iloc[i, df_15m.columns.get_loc('h1_trend')] = h1_data.get('trend_strength', 0)
                    df_15m.iloc[i, df_15m.columns.get_loc('h1_strength')] = h1_data.get('adx', 25)
            
            # Get 4H trend  
            if df_4h is not None:
                h4_data = get_aligned_timeframe_data(df_4h, current_time, '4H')
                if h4_data is not None:
                    df_15m.iloc[i, df_15m.columns.get_loc('h4_trend')] = h4_data.get('trend_strength', 0)
                    df_15m.iloc[i, df_15m.columns.get_loc('h4_strength')] = h4_data.get('adx', 25)
            
            # Get 1D trend
            if df_1d is not None:
                d1_data = get_aligned_timeframe_data(df_1d, current_time, '1D')
                if d1_data is not None:
                    df_15m.iloc[i, df_15m.columns.get_loc('d1_trend')] = d1_data.get('trend_strength', 0)
                    df_15m.iloc[i, df_15m.columns.get_loc('d1_strength')] = d1_data.get('adx', 25)
                    
        except Exception as e:
            # Continue with default values if alignment fails
            continue
    
    # Multi-timeframe alignment scores
    df_15m['mtf_bull_alignment'] = (
        (df_15m['trend_strength'] == 1).astype(int) +
        (df_15m['h1_trend'] == 1).astype(int) +
        (df_15m['h4_trend'] == 1).astype(int) +
        (df_15m['d1_trend'] == 1).astype(int)
    )
    
    df_15m['mtf_bear_alignment'] = (
        (df_15m['trend_strength'] == -1).astype(int) +
        (df_15m['h1_trend'] == -1).astype(int) +
        (df_15m['h4_trend'] == -1).astype(int) +
        (df_15m['d1_trend'] == -1).astype(int)
    )
    
    # Trend strength alignment (all timeframes showing strong trends)
    df_15m['mtf_strength_alignment'] = (
        (df_15m['adx'] > 25).astype(int) +
        (df_15m['h1_strength'] > 25).astype(int) +
        (df_15m['h4_strength'] > 25).astype(int) +
        (df_15m['d1_strength'] > 25).astype(int)
    )
    
    print(f"    ‚úÖ Multi-timeframe alignment completed")
    
    return df_15m


def get_aligned_timeframe_data(df_htf, target_time, timeframe):
    """Get the most recent higher timeframe data for alignment."""
    
    try:
        if len(df_htf) == 0:
            return None
            
        # If the higher timeframe has datetime index, find the most recent bar
        if hasattr(df_htf.index, 'to_pydatetime'):
            # Find the most recent bar before or at target_time
            valid_bars = df_htf[df_htf.index <= target_time]
            if len(valid_bars) > 0:
                latest_bar = valid_bars.iloc[-1]
                return {
                    'trend_strength': latest_bar.get('trend_strength', 0),
                    'adx': latest_bar.get('adx', 25),
                    'rsi': latest_bar.get('rsi', 50)
                }
        
        # Fallback: use the last available data
        if len(df_htf) > 0:
            latest_bar = df_htf.iloc[-1]
            return {
                'trend_strength': latest_bar.get('trend_strength', 0),
                'adx': latest_bar.get('adx', 25),
                'rsi': latest_bar.get('rsi', 50)
            }
            
    except Exception as e:
        pass
    
    return None


def add_technical_indicators(df, timeframe):
    """Add technical indicators optimized for each timeframe."""
    
    # Trend indicators (adjusted for timeframe)
    if timeframe == '15M':
        df['ema_fast'] = pta.ema(df['Close'], length=12)
        df['ema_slow'] = pta.ema(df['Close'], length=26)
        df['ema_trend'] = pta.ema(df['Close'], length=50)
    elif timeframe == '1H':
        df['ema_fast'] = pta.ema(df['Close'], length=8)
        df['ema_slow'] = pta.ema(df['Close'], length=21)
        df['ema_trend'] = pta.ema(df['Close'], length=50)
    elif timeframe == '4H':
        df['ema_fast'] = pta.ema(df['Close'], length=5)
        df['ema_slow'] = pta.ema(df['Close'], length=13)
        df['ema_trend'] = pta.ema(df['Close'], length=34)
    else:  # 1D
        df['ema_fast'] = pta.ema(df['Close'], length=3)
        df['ema_slow'] = pta.ema(df['Close'], length=8)
        df['ema_trend'] = pta.ema(df['Close'], length=21)
    
    # Momentum indicators
    df['rsi'] = pta.rsi(df['Close'], length=14)
    df['adx'] = pta.adx(df['High'], df['Low'], df['Close'], length=14).iloc[:, 0]
    df['atr'] = pta.atr(df['High'], df['Low'], df['Close'], length=14)
    
    # Trend strength
    df['trend_strength'] = np.where(
        df['ema_fast'] > df['ema_slow'], 1,
        np.where(df['ema_fast'] < df['ema_slow'], -1, 0)
    )
    
    # Momentum confirmation
    df['momentum_strength'] = np.where(
        (df['rsi'] > 50) & (df['adx'] > 25), 1,
        np.where((df['rsi'] < 50) & (df['adx'] > 25), -1, 0)
    )
    
    return df


def add_trend_filters(df_15m, df_1h, df_4h, df_1d):
    """Add multi-timeframe trend filters."""
    
    # Align timeframes (forward fill higher timeframe data)
    df_15m = df_15m.copy()
    
    # Add higher timeframe trend data
    for i, row in df_15m.iterrows():
        timestamp = row.name if hasattr(row, 'name') else i
        
        # Find corresponding higher timeframe data
        h1_trend = get_timeframe_trend(df_1h, timestamp, '1H')
        h4_trend = get_timeframe_trend(df_4h, timestamp, '4H')
        d1_trend = get_timeframe_trend(df_1d, timestamp, '1D')
        
        df_15m.loc[i, 'h1_trend'] = h1_trend
        df_15m.loc[i, 'h4_trend'] = h4_trend
        df_15m.loc[i, 'd1_trend'] = d1_trend
    
    # Multi-timeframe alignment score
    df_15m['mtf_bull_alignment'] = (
        (df_15m['trend_strength'] == 1).astype(int) +
        (df_15m['h1_trend'] == 1).astype(int) +
        (df_15m['h4_trend'] == 1).astype(int) +
        (df_15m['d1_trend'] == 1).astype(int)
    )
    
    df_15m['mtf_bear_alignment'] = (
        (df_15m['trend_strength'] == -1).astype(int) +
        (df_15m['h1_trend'] == -1).astype(int) +
        (df_15m['h4_trend'] == -1).astype(int) +
        (df_15m['d1_trend'] == -1).astype(int)
    )
    
    return df_15m


def get_timeframe_trend(df_htf, timestamp, timeframe):
    """Get trend from higher timeframe for given timestamp."""
    try:
        if len(df_htf) == 0:
            return 0
        
        # For simplicity, use the last available trend
        if 'trend_strength' in df_htf.columns:
            return df_htf['trend_strength'].iloc[-1] if len(df_htf) > 0 else 0
        else:
            return 0
    except:
        return 0


def add_session_analysis(df):
    """Add trading session analysis."""
    
    # Create hour column if not exists
    if not hasattr(df.index, 'hour'):
        df['hour'] = 12  # Default hour
    else:
        df['hour'] = df.index.hour
    
    # Trading sessions (UTC time)
    df['asian_session'] = ((df['hour'] >= 0) & (df['hour'] <= 8)).astype(int)
    df['london_session'] = ((df['hour'] >= 8) & (df['hour'] <= 16)).astype(int)
    df['ny_session'] = ((df['hour'] >= 13) & (df['hour'] <= 21)).astype(int)
    df['overlap_session'] = ((df['hour'] >= 13) & (df['hour'] <= 16)).astype(int)
    
    # Session volatility
    df['high_liquidity'] = (df['london_session'] | df['ny_session']).astype(int)
    df['low_liquidity'] = df['asian_session'].astype(int)
    
    return df


def add_news_sentiment(df):
    """Add news sentiment analysis."""
    
    news_analyzer = NewsAnalyzer()
    
    # Add news sentiment for each bar
    sentiments = []
    impacts = []
    risk_on_scores = []
    
    for i in range(len(df)):
        # Create a date for sentiment analysis
        if hasattr(df.index, 'date'):
            date = df.index[i]
        else:
            # Use a base date and add days
            base_date = datetime(2023, 1, 1)
            date = base_date + timedelta(days=i // 96)  # 96 bars per day (15M)
        
        news_data = news_analyzer.get_news_sentiment(date)
        sentiments.append(news_data['sentiment'])
        impacts.append(1 if news_data['impact'] == 'high' else 0.5 if news_data['impact'] == 'medium' else 0)
        risk_on_scores.append(news_data['risk_on'])
    
    df['news_sentiment'] = sentiments
    df['news_impact'] = impacts
    df['risk_on'] = risk_on_scores
    
    return df


def create_institutional_signals(df):
    """Create institutional-grade trading signals."""
    
    # Multi-timeframe trend confirmation (minimum 3/4 timeframes aligned)
    strong_bull_trend = df['mtf_bull_alignment'] >= 3
    strong_bear_trend = df['mtf_bear_alignment'] >= 3
    
    # News filter (avoid trading during high impact news unless aligned)
    news_filter_bull = (
        (df['news_impact'] < 0.8) |  # Low/medium impact news
        ((df['news_impact'] >= 0.8) & (df['news_sentiment'] > 0.2))  # High impact bullish news
    )
    
    news_filter_bear = (
        (df['news_impact'] < 0.8) |  # Low/medium impact news
        ((df['news_impact'] >= 0.8) & (df['news_sentiment'] < -0.2))  # High impact bearish news
    )
    
    # Session filter (prefer high liquidity sessions)
    session_filter = df['high_liquidity'] == 1
    
    # Risk sentiment filter for gold
    risk_filter_bull = df['risk_on'] < 0.6  # Risk-off favors gold
    risk_filter_bear = df['risk_on'] > 0.4  # Risk-on can pressure gold
    
    # Technical confirmation
    tech_bull = (
        (df['rsi'] > 45) & (df['rsi'] < 70) &
        (df['adx'] > 25) &
        (df['Close'] > df['ema_fast']) &
        (df['ema_fast'] > df['ema_slow'])
    )
    
    tech_bear = (
        (df['rsi'] < 55) & (df['rsi'] > 30) &
        (df['adx'] > 25) &
        (df['Close'] < df['ema_fast']) &
        (df['ema_fast'] < df['ema_slow'])
    )
    
    # INSTITUTIONAL SIGNAL SCORING (15 conditions for maximum precision)
    bull_score = (
        strong_bull_trend.astype(int) * 4 +  # Multi-timeframe alignment (4 points)
        tech_bull.astype(int) * 3 +          # Technical confirmation (3 points)
        news_filter_bull.astype(int) * 2 +   # News filter (2 points)
        session_filter.astype(int) * 2 +     # Session filter (2 points)
        risk_filter_bull.astype(int) * 2 +   # Risk sentiment (2 points)
        (df['momentum_strength'] == 1).astype(int) * 2  # Momentum (2 points)
    )
    
    bear_score = (
        strong_bear_trend.astype(int) * 4 +  # Multi-timeframe alignment (4 points)
        tech_bear.astype(int) * 3 +          # Technical confirmation (3 points)
        news_filter_bear.astype(int) * 2 +   # News filter (2 points)
        session_filter.astype(int) * 2 +     # Session filter (2 points)
        risk_filter_bear.astype(int) * 2 +   # Risk sentiment (2 points)
        (df['momentum_strength'] == -1).astype(int) * 2  # Momentum (2 points)
    )
    
    # Store scores
    df['bull_score'] = bull_score
    df['bear_score'] = bear_score
    
    # INSTITUTIONAL THRESHOLDS (12+ out of 15 for ultra-high probability)
    df['institutional_bull'] = (bull_score >= 12).astype(int)
    df['institutional_bear'] = (bear_score >= 12).astype(int)
    df['high_prob_bull'] = (bull_score >= 10).astype(int)
    df['high_prob_bear'] = (bear_score >= 10).astype(int)
    df['medium_prob_bull'] = (bull_score >= 8).astype(int)
    df['medium_prob_bear'] = (bear_score >= 8).astype(int)
    
    return df


# ============================================================================
# ENHANCED TRADING ENVIRONMENT
# ============================================================================

class InstitutionalTradingEnv(gym.Env):
    """Institutional-grade trading environment with multi-timeframe analysis."""
    
    def __init__(self, df, window_size=25, initial_balance=10000.0,
                 atr_mult=1.0, institutional_mode=True, curriculum_stage=1):
        super().__init__()
        
        self.df = df.reset_index(drop=True)
        self.n_steps = len(self.df)
        self.window_size = window_size
        self.initial_balance = initial_balance
        self.atr_mult = atr_mult
        self.institutional_mode = institutional_mode
        self.curriculum_stage = curriculum_stage
        
        # Actions: 0=Hold, 1=Buy, 2=Sell
        self.action_space = spaces.Discrete(3)
        
        # Enhanced feature set for institutional trading
        self.feature_columns = [
            'Close', 'Volume', 'rsi', 'adx', 'atr',
            'ema_fast', 'ema_slow', 'bull_score', 'bear_score',
            'mtf_bull_alignment', 'mtf_bear_alignment',
            'news_sentiment', 'news_impact', 'risk_on',
            'high_liquidity', 'overlap_session'
        ]
        self.num_features = len(self.feature_columns)
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf,
            shape=(window_size, self.num_features + 3),
            dtype=np.float32
        )
        
        # Pre-allocate buffers
        self._obs_buffer = np.zeros((window_size, self.num_features + 3), dtype=np.float32)
        self._feature_buffer = np.zeros((window_size, self.num_features), dtype=np.float32)
        
        self._init_state()
    
    def _init_state(self):
        if self.n_steps > self.window_size + 200:
            self.current_step = np.random.randint(self.window_size, self.n_steps - 200)
        else:
            self.current_step = self.window_size
        
        self.balance = self.initial_balance
        self.position = None
        self.entry_price = 0.0
        self.entry_atr = 0.0
        self.total_trades = 0
        self.wins = 0
        self.losses = 0
        self.consecutive_losses = 0
        self.consecutive_wins = 0
        self.episode_steps = 0
        self.max_episode_steps = min(400, self.n_steps - self.current_step - 1)
        self.last_trade_step = -25  # Longer cooldown for institutional approach
        self.peak_balance = self.initial_balance
    
    def _get_signal_requirements(self):
        """Institutional signal requirements."""
        if not hasattr(self, '_cached_requirements') or self._cached_stage != self.curriculum_stage:
            if self.curriculum_stage == 1:  # Start with high probability
                self._cached_requirements = {'institutional': False, 'min_score': 8}
            elif self.curriculum_stage == 2:  # Increase to institutional grade
                self._cached_requirements = {'institutional': True, 'min_score': 10}
            else:  # Ultra-institutional
                self._cached_requirements = {'institutional': True, 'min_score': 12}
            self._cached_stage = self.curriculum_stage
        return self._cached_requirements
    
    def _get_obs(self):
        """Optimized observation generation."""
        start = max(0, self.current_step - self.window_size)
        end = self.current_step
        
        obs_data = self.df[self.feature_columns].iloc[start:end].values
        
        if len(obs_data) < self.window_size:
            pad_size = self.window_size - len(obs_data)
            self._feature_buffer[:pad_size] = 0
            self._feature_buffer[pad_size:] = obs_data
        else:
            self._feature_buffer[:] = obs_data
        
        # Context features
        self._obs_buffer[:, :-3] = self._feature_buffer
        
        # Position encoding
        if self.position == 'long':
            self._obs_buffer[:, -3] = 1.0
        elif self.position == 'short':
            self._obs_buffer[:, -3] = -1.0
        else:
            self._obs_buffer[:, -3] = 0.0
        
        # Trade count and win rate
        self._obs_buffer[:, -2] = min(self.total_trades / 10.0, 1.0)
        self._obs_buffer[:, -1] = self.wins / max(1, self.total_trades)
        
        # Clean and clip
        np.nan_to_num(self._obs_buffer, copy=False, nan=0.0, posinf=3.0, neginf=-3.0)
        np.clip(self._obs_buffer, -5.0, 5.0, out=self._obs_buffer)
        
        return self._obs_buffer.copy()
    
    def step(self, action):
        reward = 0.0
        done = False
        
        if self.current_step >= len(self.df) - 1:
            return self._get_obs(), 0.0, True, False, self._get_info()
        
        # Get current market data
        current_data = self.df.iloc[self.current_step]
        price = current_data['Close']
        high = current_data['High']
        low = current_data['Low']
        bull_score = current_data['bull_score']
        bear_score = current_data['bear_score']
        institutional_bull = current_data['institutional_bull']
        institutional_bear = current_data['institutional_bear']
        news_impact = current_data['news_impact']
        
        # Check exit conditions
        if self.position:
            closed, pnl, is_win = self._check_exit_fast(high, low, price)
            if closed:
                self.total_trades += 1
                
                if is_win:
                    self.wins += 1
                    self.consecutive_losses = 0
                    self.consecutive_wins += 1
                    
                    # INSTITUTIONAL WIN REWARDS (targeting 75%+ WR)
                    base_reward = 150.0  # Higher base reward
                    
                    # Win rate bonuses (heavily weighted)
                    if self.total_trades >= 3:
                        current_wr = self.wins / self.total_trades
                        if current_wr >= 0.8:
                            base_reward += 100.0  # Massive bonus for 80%+
                        elif current_wr >= 0.75:
                            base_reward += 75.0   # Large bonus for 75%+
                        elif current_wr >= 0.7:
                            base_reward += 50.0   # Good bonus for 70%+
                    
                    # News impact bonus (reward trading during favorable news)
                    if news_impact > 0.8:
                        base_reward += 25.0
                    
                    reward = base_reward
                    
                else:
                    self.losses += 1
                    self.consecutive_wins = 0
                    self.consecutive_losses += 1
                    
                    # SEVERE penalties for institutional losses
                    penalty = -80.0
                    
                    # Win rate penalties
                    if self.total_trades >= 3:
                        current_wr = self.wins / self.total_trades
                        if current_wr < 0.6:
                            penalty -= 60.0
                        elif current_wr < 0.7:
                            penalty -= 30.0
                    
                    # News impact penalty (avoid trading against major news)
                    if news_impact > 0.8:
                        penalty -= 30.0
                    
                    reward = penalty - (self.consecutive_losses * 25)
                
                # Update balance
                self.balance *= (1 + pnl * 0.02)
                self.position = None
                self.entry_price = 0.0
                self.entry_atr = 0.0
        
        # INSTITUTIONAL TRADING LOGIC
        requirements = self._get_signal_requirements()
        cooldown = 25  # Longer cooldown for institutional approach
        
        can_trade = (
            (self.current_step - self.last_trade_step) >= cooldown and
            self.position is None and
            self.consecutive_losses < 2 and  # Very conservative
            current_data['high_liquidity'] == 1  # Only trade during high liquidity
        )
        
        if can_trade:
            if action == 1:  # Buy
                signal_valid = False
                
                if requirements['institutional']:
                    signal_valid = institutional_bull == 1
                else:
                    signal_valid = bull_score >= requirements['min_score']
                
                if signal_valid:
                    self.position = 'long'
                    self.entry_price = price
                    self.entry_atr = self._get_atr_fast()
                    self.last_trade_step = self.current_step
                    
                    # Institutional signal rewards
                    if institutional_bull == 1:
                        reward += 40.0  # Massive reward for institutional signals
                    else:
                        reward += 25.0 + (bull_score - 8) * 3
                    
                else:
                    # Heavy penalties for poor institutional signals
                    reward -= 30.0 if bull_score < 8 else -15.0
                        
            elif action == 2:  # Sell
                signal_valid = False
                
                if requirements['institutional']:
                    signal_valid = institutional_bear == 1
                else:
                    signal_valid = bear_score >= requirements['min_score']
                
                if signal_valid:
                    self.position = 'short'
                    self.entry_price = price
                    self.entry_atr = self._get_atr_fast()
                    self.last_trade_step = self.current_step
                    
                    # Institutional signal rewards
                    if institutional_bear == 1:
                        reward += 40.0  # Massive reward for institutional signals
                    else:
                        reward += 25.0 + (bear_score - 8) * 3
                    
                else:
                    # Heavy penalties for poor institutional signals
                    reward -= 30.0 if bear_score < 8 else -15.0
            
            else:  # Hold
                # Reward institutional patience
                max_score = max(bull_score, bear_score)
                if max_score < requirements['min_score']:
                    reward += 3.0  # Good patience
                elif institutional_bull == 1 or institutional_bear == 1:
                    reward -= 15.0  # Heavy penalty for missing institutional signals
                else:
                    reward -= 5.0   # Moderate penalty for missing good signals
        
        # Risk management
        if self.balance > self.peak_balance:
            self.peak_balance = self.balance
        
        if (self.peak_balance - self.balance) / self.peak_balance > 0.15:
            done = True
            reward -= 150.0
        
        # Episode management
        self.current_step += 1
        self.episode_steps += 1
        
        if self.current_step >= self.n_steps - 1 or self.episode_steps >= self.max_episode_steps:
            done = True
        
        return self._get_obs(), float(np.clip(reward, -300, 300)), done, False, self._get_info()
    
    def _get_atr_fast(self):
        """Fast ATR calculation."""
        atr = self.df.iloc[self.current_step]['atr']
        return max(float(atr) if not np.isnan(atr) else 0.01, 0.001)
    
    def _check_exit_fast(self, high, low, current_price):
        """Fast exit check with 1:1 risk/reward."""
        if not self.position or self.entry_price == 0 or self.entry_atr <= 0:
            return False, 0.0, False
        
        distance = self.entry_atr * self.atr_mult
        
        if self.position == 'long':
            if high >= self.entry_price + distance:
                return True, distance / abs(self.entry_price), True
            if low <= self.entry_price - distance:
                return True, -distance / abs(self.entry_price), False
        else:
            if low <= self.entry_price - distance:
                return True, distance / abs(self.entry_price), True
            if high >= self.entry_price + distance:
                return True, -distance / abs(self.entry_price), False
        
        return False, 0.0, False
    
    def _get_info(self):
        return {
            'win_rate': self.wins / max(1, self.total_trades),
            'total_trades': self.total_trades,
            'wins': self.wins,
            'losses': self.losses,
            'balance': self.balance,
            'return_pct': (self.balance - self.initial_balance) / self.initial_balance * 100,
            'consecutive_wins': self.consecutive_wins,
            'consecutive_losses': self.consecutive_losses,
            'curriculum_stage': self.curriculum_stage
        }
    
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self._init_state()
        return self._get_obs(), {}


# ============================================================================
# INSTITUTIONAL CALLBACK
# ============================================================================

class InstitutionalCallback(BaseCallback):
    """Institutional-grade callback targeting 75%+ win rate."""
    
    def __init__(self, val_df, eval_freq=4000, save_path="models/experimental"):
        super().__init__()
        self.val_df = val_df
        self.eval_freq = eval_freq
        self.save_path = save_path
        
        self.best_wr = 0.0
        self.best_score = -np.inf
        self.curriculum_stage = 1
        self.stage_performance = []
        self.no_improve_count = 0
        self.evaluation_history = []
    
    def _on_step(self):
        if self.num_timesteps % self.eval_freq == 0:
            val_wr, val_trades, val_return = self._evaluate_institutional()
            
            # Institutional scoring (heavily weighted toward win rate)
            score = val_wr * 0.9 + max(0, val_return/100) * 0.1
            
            print(f"\nüèõÔ∏è INSTITUTIONAL EVALUATION at {self.num_timesteps:,} steps:")
            print(f"   Win Rate: {val_wr*100:.1f}%")
            print(f"   Trades: {val_trades:.1f}")
            print(f"   Return: {val_return:+.1f}%")
            print(f"   Score: {score:.3f}")
            print(f"   Curriculum Stage: {self.curriculum_stage}")
            
            # Save if improved
            if score > self.best_score and val_trades >= 2:
                self.best_score = score
                self.best_wr = val_wr
                self.no_improve_count = 0
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_name = f"institutional_mtf_v4_wr{val_wr*100:.0f}_{timestamp}"
                self.model.save(f"{self.save_path}/{model_name}")
                
                print(f"üèÜ NEW INSTITUTIONAL BEST: {model_name}")
                
                # Move to production if exceptional (75%+ WR)
                if val_wr >= 0.75 and val_trades >= 3:
                    os.makedirs("models/production", exist_ok=True)
                    self.model.save(f"models/production/{model_name}")
                    print(f"üèõÔ∏è MOVED TO INSTITUTIONAL PRODUCTION!")
                    
            else:
                self.no_improve_count += 1
            
            # Curriculum progression (institutional standards)
            self.stage_performance.append(val_wr)
            
            if len(self.stage_performance) >= 4:
                recent_avg = np.mean(self.stage_performance[-4:])
                
                if self.curriculum_stage == 1 and recent_avg >= 0.65:
                    self.curriculum_stage = 2
                    print(f"üìà INSTITUTIONAL CURRICULUM ADVANCED TO STAGE 2 (65%+ WR)")
                    self._update_env_curriculum()
                    
                elif self.curriculum_stage == 2 and recent_avg >= 0.72:
                    self.curriculum_stage = 3
                    print(f"üìà INSTITUTIONAL CURRICULUM ADVANCED TO STAGE 3 (72%+ WR)")
                    self._update_env_curriculum()
            
            # Store evaluation
            self.evaluation_history.append({
                'timestep': self.num_timesteps,
                'win_rate': val_wr,
                'trades': val_trades,
                'return': val_return,
                'score': score,
                'stage': self.curriculum_stage
            })
            
            # Early stopping
            if self.no_improve_count >= 15:
                print(f"\nüõë Institutional early stopping - no improvement for 15 evaluations")
                return False
        
        return True
    
    def _update_env_curriculum(self):
        """Update environment curriculum stage."""
        if hasattr(self.model.env, 'envs'):
            for env in self.model.env.envs:
                if hasattr(env, 'curriculum_stage'):
                    env.curriculum_stage = self.curriculum_stage
    
    def _evaluate_institutional(self):
        """Institutional evaluation with higher standards."""
        episodes_data = []
        
        for episode in range(8):
            env = InstitutionalTradingEnv(
                df=self.val_df,
                curriculum_stage=self.curriculum_stage
            )
            
            obs, _ = env.reset()
            done = False
            step_count = 0
            max_steps = 250
            
            while not done and step_count < max_steps:
                action, _ = self.model.predict(obs, deterministic=True)
                obs, _, done, _, info = env.step(action)
                step_count += 1
            
            if info.get('total_trades', 0) > 0:
                episodes_data.append(info)
        
        if not episodes_data:
            return 0.4, 0, -15
        
        # Calculate institutional metrics
        total_trades = sum(ep['total_trades'] for ep in episodes_data)
        total_wins = sum(ep['wins'] for ep in episodes_data)
        returns = [ep['return_pct'] for ep in episodes_data]
        
        win_rate = total_wins / max(1, total_trades)
        avg_trades = total_trades / len(episodes_data)
        avg_return = np.mean(returns) if returns else 0
        
        return win_rate, avg_trades, avg_return


# ============================================================================
# MAIN TRAINING FUNCTION
# ============================================================================

def load_and_prepare_institutional_data(base_path="data/raw"):
    """Load and prepare data with institutional multi-timeframe analysis using real files."""
    print(f"üèõÔ∏è Loading institutional multi-timeframe data from: {base_path}")
    
    # Load all timeframes from your actual files
    timeframe_data = load_multi_timeframe_data(base_path)
    
    # Use 15M as base timeframe for execution
    df_15m = timeframe_data['15M']
    df_1h = timeframe_data['1H']
    df_4h = timeframe_data['4H']
    df_1d = timeframe_data['1D']
    
    if df_15m is None:
        raise ValueError("15M data is required but not found!")
    
    print(f"üìä Base 15M data: {len(df_15m)} bars")
    
    # Create institutional multi-timeframe signals using real data
    df = create_multi_timeframe_signals(df_15m, df_1h, df_4h, df_1d)
    
    # Normalize data for training
    print("üßπ Normalizing institutional data...")
    
    # Normalize prices
    first_valid_idx = df['Close'].first_valid_index()
    if first_valid_idx is not None:
        base_price = df.loc[first_valid_idx, 'Close']
        for col in ['Open', 'High', 'Low', 'Close']:
            if col in df.columns:
                df[col] = (df[col] / base_price - 1) * 100
    
    # Normalize other features
    for col in ['rsi', 'adx', 'news_sentiment']:
        if col in df.columns and df[col].std() > 0:
            df[col] = (df[col] - df[col].mean()) / df[col].std()
            df[col] = df[col].clip(-3, 3)
    
    # Clean data
    df = df.dropna().reset_index(drop=True)
    df = df.replace([np.inf, -np.inf], 0).fillna(0)
    
    print(f"‚úÖ Final institutional dataset: {len(df)} bars")
    
    # Multi-timeframe signal statistics
    institutional_bull = (df['institutional_bull'] == 1).sum()
    institutional_bear = (df['institutional_bear'] == 1).sum()
    mtf_bull_3plus = (df['mtf_bull_alignment'] >= 3).sum()
    mtf_bear_3plus = (df['mtf_bear_alignment'] >= 3).sum()
    
    print(f"üèõÔ∏è Institutional Multi-Timeframe Analysis:")
    print(f"   Institutional Bull Signals: {institutional_bull} ({institutional_bull/len(df)*100:.2f}%)")
    print(f"   Institutional Bear Signals: {institutional_bear} ({institutional_bear/len(df)*100:.2f}%)")
    print(f"   Multi-TF Bull Alignment (3+): {mtf_bull_3plus} ({mtf_bull_3plus/len(df)*100:.2f}%)")
    print(f"   Multi-TF Bear Alignment (3+): {mtf_bear_3plus} ({mtf_bear_3plus/len(df)*100:.2f}%)")
    
    return df


def make_institutional_env(df, curriculum_stage=1):
    def _init():
        env = InstitutionalTradingEnv(df=df, curriculum_stage=curriculum_stage)
        return Monitor(env)
    return _init


def train_institutional_mtf(
    base_path="data/raw",
    timesteps=800000,
    n_envs=6,
    eval_freq=4000
):
    """Train institutional multi-timeframe model using real timeframe data."""
    
    print("=" * 80)
    print("üèõÔ∏è INSTITUTIONAL MULTI-TIMEFRAME TRADING MODEL V4")
    print("=" * 80)
    print(f"Target: 75%+ win rate with institutional-grade analysis")
    print(f"Approach: Real Multi-timeframe (1D/4H/1H‚Üí15M) + News + Sessions")
    
    # Load and prepare institutional data using your actual files
    df = load_and_prepare_institutional_data(base_path)
    
    # Split data
    train_size = int(len(df) * 0.7)
    val_size = int(len(df) * 0.2)
    
    train_df = df.iloc[:train_size].reset_index(drop=True)
    val_df = df.iloc[train_size:train_size+val_size].reset_index(drop=True)
    
    print(f"\nüìä Institutional Data Split:")
    print(f"   Train: {len(train_df):,} bars")
    print(f"   Validation: {len(val_df):,} bars")
    
    # Create institutional environments
    print(f"\nüèóÔ∏è Creating {n_envs} institutional environments...")
    env = DummyVecEnv([make_institutional_env(train_df, curriculum_stage=1) for _ in range(n_envs)])
    env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=3.0)
    
    # Institutional model configuration
    policy_kwargs = dict(
        net_arch=dict(pi=[768, 384, 192], vf=[768, 384, 192]),  # Larger network for complex analysis
        activation_fn=nn.ReLU
    )
    
    model = PPO(
        "MlpPolicy",
        env,
        learning_rate=1.5e-4,  # Lower learning rate for stability
        n_steps=384,           # Balanced for institutional approach
        batch_size=768,        # Larger batch for stability
        n_epochs=8,            # Balanced epochs
        gamma=0.995,           # Slightly higher gamma for longer-term thinking
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.005,        # Lower entropy for more focused learning
        vf_coef=0.5,
        max_grad_norm=0.5,
        policy_kwargs=policy_kwargs,
        verbose=1,
        tensorboard_log="logs/institutional_mtf_v4_training"
    )
    
    # Create directories
    os.makedirs("models/experimental", exist_ok=True)
    
    # Institutional callback
    callback = InstitutionalCallback(
        val_df=val_df,
        eval_freq=eval_freq,
        save_path="models/experimental"
    )
    
    print("\nüèõÔ∏è Starting institutional multi-timeframe training...")
    print("=" * 80)
    
    try:
        model.learn(total_timesteps=timesteps, callback=callback, progress_bar=True)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Institutional training interrupted by user")
    
    # Save final model
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_name = f"institutional_mtf_v4_final_{timestamp}"
    model.save(f"models/experimental/{final_name}")
    
    print(f"\nüíæ Final institutional model saved: {final_name}")
    print(f"üèõÔ∏è Best institutional win rate: {callback.best_wr*100:.1f}%")
    
    return model, callback.evaluation_history


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Institutional Multi-Timeframe Trading Model V4")
    parser.add_argument('--timesteps', type=int, default=800000, help='Training timesteps')
    parser.add_argument('--envs', type=int, default=6, help='Number of environments')
    parser.add_argument('--eval-freq', type=int, default=4000, help='Evaluation frequency')
    
    args = parser.parse_args()
    
    print(f"üèõÔ∏è Starting Institutional Multi-Timeframe Model V4 Training")
    print(f"Target: 75%+ win rate with professional-grade analysis")
    
    model, history = train_institutional_mtf(
        timesteps=args.timesteps,
        n_envs=args.envs,
        eval_freq=args.eval_freq
    )
    
    print("\nüéâ Institutional training completed!")
    if history:
        best_eval = max(history, key=lambda x: x['win_rate'])
        print(f"üèõÔ∏è Best institutional validation: {best_eval['win_rate']*100:.1f}% win rate")